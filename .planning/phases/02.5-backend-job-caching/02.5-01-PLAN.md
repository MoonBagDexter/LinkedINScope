---
phase: 02.5-backend-job-caching
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - supabase/functions/job-sync/index.ts
  - supabase/migrations/20260202_add_job_caching.sql
autonomous: true

user_setup:
  - service: supabase-cli
    why: "Edge Function deployment requires Supabase CLI"
    env_vars:
      - name: SUPABASE_ACCESS_TOKEN
        source: "Supabase Dashboard -> Account -> Access Tokens -> Generate"
    dashboard_config:
      - task: "Link project to CLI"
        location: "Run: supabase link --project-ref YOUR_PROJECT_REF"
  - service: jsearch
    why: "JSearch API key needed in Edge Function secrets"
    env_vars:
      - name: JSEARCH_API_KEY
        source: "Already have from Phase 1 - same key used in VITE_JSEARCH_API_KEY"
    dashboard_config:
      - task: "Add JSEARCH_API_KEY to Edge Function secrets"
        location: "Supabase Dashboard -> Edge Functions -> Secrets OR via CLI: supabase secrets set JSEARCH_API_KEY=your_key"

must_haves:
  truths:
    - "Edge Function fetches jobs from JSearch API successfully"
    - "Jobs are stored in Supabase with is_active and last_seen columns"
    - "Existing jobs preserve click_count and lane on upsert"
    - "Stale jobs marked inactive (not deleted)"
  artifacts:
    - path: "supabase/functions/job-sync/index.ts"
      provides: "Edge Function handler for job sync"
      contains: "Deno.serve"
    - path: "supabase/migrations/20260202_add_job_caching.sql"
      provides: "Schema migration for caching columns"
      contains: "is_active"
  key_links:
    - from: "supabase/functions/job-sync/index.ts"
      to: "JSearch API"
      via: "fetch with X-RapidAPI headers"
      pattern: "jsearch.p.rapidapi.com"
    - from: "supabase/functions/job-sync/index.ts"
      to: "Supabase jobs table"
      via: "service_role_key client"
      pattern: "SUPABASE_SERVICE_ROLE_KEY"
---

<objective>
Create Supabase Edge Function that fetches jobs from JSearch API and stores them in the database with proper upsert logic that preserves engagement data.

Purpose: Moves job fetching from per-user client calls to a backend service, enabling 90%+ reduction in API quota usage and sub-2-second page loads.

Output: Deployed Edge Function accessible at /functions/v1/job-sync that can be triggered manually or via cron.
</objective>

<execution_context>
@C:\Users\thedi\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\thedi\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02.5-backend-job-caching/02.5-CONTEXT.md
@.planning/phases/02.5-backend-job-caching/02.5-RESEARCH.md

@src/types/job.ts
@src/services/jsearch.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Database schema migration for job caching</name>
  <files>supabase/migrations/20260202_add_job_caching.sql</files>
  <action>
Create SQL migration file that adds caching support columns to the jobs table:

1. Add `is_active BOOLEAN DEFAULT TRUE NOT NULL` column - marks whether job is currently in JSearch API results
2. Add `last_seen TIMESTAMPTZ DEFAULT NOW()` column - tracks last time job appeared in API refresh
3. Create index on `is_active` for fast filtering: `CREATE INDEX idx_jobs_is_active ON jobs(is_active)`
4. Add column comments for documentation

Also ensure the jobs table has all JSearch fields needed for full job data storage (extending from click tracking):
- job_id (already exists as primary key from Phase 2)
- job_title, employer_name, job_city, job_state, job_country, job_apply_link
- job_min_salary, job_max_salary, job_salary_currency, job_salary_period (nullable)
- employer_logo, job_description (nullable)

Use ALTER TABLE with IF NOT EXISTS patterns for idempotent migrations.

IMPORTANT: Do NOT include click_count or lane in any INSERT/UPDATE - these must be preserved from existing engagement data.
  </action>
  <verify>
Run migration in Supabase SQL Editor:
1. Copy migration file contents
2. Execute in Supabase Dashboard -> SQL Editor
3. Verify columns exist: `SELECT column_name FROM information_schema.columns WHERE table_name = 'jobs'`
4. Verify index exists: `SELECT indexname FROM pg_indexes WHERE tablename = 'jobs'`
  </verify>
  <done>
- jobs table has is_active (boolean, default true)
- jobs table has last_seen (timestamptz)
- idx_jobs_is_active index exists
- All JSearch job fields are present in table
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Supabase Edge Function for job sync</name>
  <files>supabase/functions/job-sync/index.ts</files>
  <action>
Create the Edge Function following Deno runtime conventions:

1. Initialize Supabase CLI project structure:
   - Create `supabase/` directory if not exists
   - Create `supabase/functions/job-sync/` directory

2. Create `index.ts` with:

```typescript
// Import from esm.sh for Deno compatibility (NOT npm imports)
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';

// Type definitions matching src/types/job.ts
interface JSearchJob {
  job_id: string;
  job_title: string;
  employer_name: string;
  job_city: string;
  job_state: string;
  job_country: string;
  job_apply_link: string;
  job_min_salary?: number;
  job_max_salary?: number;
  job_salary_currency?: string;
  job_salary_period?: string;
  employer_logo?: string;
  job_description?: string;
}
```

3. Implement Deno.serve() handler:
   - Create Supabase client with SUPABASE_SERVICE_ROLE_KEY (bypasses RLS)
   - Fetch jobs from JSearch API using native fetch (NOT axios)
   - Query: `fast+food+crew+member+USA`, num_pages=1
   - Mark all existing active jobs as inactive first
   - Upsert jobs with onConflict: 'job_id', explicitly setting is_active: true, last_seen: new Date()
   - Do NOT include click_count or lane in upsert (preserves existing values)
   - Return JSON response with success status, job count, timestamp

4. Implement fetchWithRetry helper:
   - Max 3 retries
   - Exponential backoff: 10ms, 20ms, 40ms + jitter (30%)
   - Only retry on 429 (rate limit) or 5xx errors
   - Log attempt count for debugging

5. Error handling:
   - Catch all errors
   - Return 500 with error message JSON
   - Log errors with [job-sync] prefix

Use Deno.env.get() for environment variables:
- SUPABASE_URL (auto-injected by Supabase)
- SUPABASE_SERVICE_ROLE_KEY (auto-injected by Supabase)
- JSEARCH_API_KEY (must be added as secret)

CRITICAL: Use native `fetch`, NOT axios. Axios is incompatible with Deno runtime.
  </action>
  <verify>
Local testing:
1. `npm install -g supabase` (if not already installed)
2. `supabase init` (in project root if not already initialized)
3. `supabase functions serve job-sync --env-file .env.local`
4. In another terminal: `curl -X POST http://localhost:54321/functions/v1/job-sync -H "Authorization: Bearer $SUPABASE_ANON_KEY"`
5. Verify response: `{"success": true, "jobCount": N, "timestamp": "..."}`

Note: Full test requires JSEARCH_API_KEY in environment. If not available locally, test will fail with API error - this is expected.
  </verify>
  <done>
- supabase/functions/job-sync/index.ts exists
- Function uses Deno.serve() pattern
- Function uses native fetch (not axios)
- Function uses service_role_key for DB access
- Upsert preserves click_count and lane (not included in payload)
- Error handling returns 500 with JSON error
  </done>
</task>

<task type="auto">
  <name>Task 3: Deploy Edge Function and verify with manual trigger</name>
  <files>supabase/functions/job-sync/index.ts</files>
  <action>
Deploy the Edge Function to Supabase and verify it works:

1. Link Supabase project (if not already linked):
   ```bash
   supabase link --project-ref YOUR_PROJECT_REF
   ```
   (Get project ref from Supabase Dashboard URL: https://app.supabase.com/project/YOUR_PROJECT_REF)

2. Add JSEARCH_API_KEY to Edge Function secrets:
   ```bash
   supabase secrets set JSEARCH_API_KEY=your_jsearch_api_key
   ```
   (Use same key from VITE_JSEARCH_API_KEY in .env.local)

3. Deploy the function:
   ```bash
   supabase functions deploy job-sync
   ```

4. Test manual invocation:
   ```bash
   curl -X POST "https://YOUR_PROJECT_REF.supabase.co/functions/v1/job-sync" \
     -H "Authorization: Bearer YOUR_SERVICE_ROLE_KEY" \
     -H "Content-Type: application/json" \
     -d '{"manual": true}'
   ```

5. Verify jobs were synced:
   - Check Supabase Dashboard -> Table Editor -> jobs
   - Verify new columns: is_active, last_seen
   - Verify job data populated

If deployment fails due to auth, Claude should create a checkpoint for user to authenticate.
  </action>
  <verify>
1. `supabase functions list` shows job-sync as deployed
2. Manual curl invocation returns `{"success": true, "jobCount": N, "timestamp": "..."}`
3. Supabase jobs table has rows with is_active=true and recent last_seen timestamps
4. Edge Function logs show successful execution: Dashboard -> Edge Functions -> job-sync -> Logs
  </verify>
  <done>
- Edge Function deployed to production Supabase
- Manual trigger returns success response
- Jobs visible in Supabase table with is_active=true
- No errors in Edge Function logs
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Edge Function accessible at /functions/v1/job-sync
2. Manual POST request triggers job sync
3. Jobs table populated with full job data + caching columns
4. Existing click_count and lane values preserved (if any jobs existed)
5. Stale jobs (not in current API response) have is_active=false
</verification>

<success_criteria>
- Edge Function deployed and callable
- Jobs stored in Supabase with all JSearch fields
- Upsert logic preserves engagement data
- Manual trigger works for testing
- Ready for pg_cron scheduling (Plan 02)
</success_criteria>

<output>
After completion, create `.planning/phases/02.5-backend-job-caching/02.5-01-SUMMARY.md`
</output>
